library(dplyr)
library(xlsx)
library(tm)
library(NLP)
library(caret)
source("utils.R",local = TRUE)
source("RArabicStemmer.R")
Sys.setlocale("LC_ALL", "Arabic")
set.seed(32323)
unclean.corpus <- read.csv("data/corpus_train.csv",encoding = "UTF-8")
#arabic.lexicon <- read.xlsx("data/sentimentLex.xlsx",sheetIndex = 1,encoding = "UTF-8")
arabic.stopword.df <- read.table("data/arabicStops.txt", encoding = "UTF-8")
arabic.stopword <- as.character((arabic.stopword.df$V1))
stemmer <- getArabicStemmer()
twitter.corpus <- Corpus(VectorSource(unclean.corpus$tweet))
twitter.corpus.clean <- tm_map(twitter.corpus, tolower)
twitter.corpus.clean <- tm_map(twitter.corpus.clean, removeNumbers)
twitter.corpus.clean <- tm_map(twitter.corpus.clean, removeWords,arabic.stopword)
twitter.corpus.clean <- tm_map(twitter.corpus.clean, removePunctuation)
twitter.corpus.clean <- tm_map(twitter.corpus.clean, removeEnglishWords)
twitter.corpus.clean <- tm_map(twitter.corpus.clean, stripWhitespace)
twitter.corpus.clean <- tm_map(twitter.corpus.clean, reomveElongation)
twitter.corpus.clean <- tm_map(twitter.corpus.clean, reomveSingleLetters)
twitter.corpus.clean <- tm_map(twitter.corpus.clean, stemWord, stemmer )
library(rJava)
getArabicStemmer <- function(){
.jinit('.')
.jaddClassPath("ArabicStemmer.jar")
Stemmer <- .jnew("elbeltagyRafea/SimpleArStemmer")
return(Stemmer)
}
stemWord <- function(Stemmer, word){
jword <- .jnew('java/lang/String', word)
out   <- .jcall(Stemmer, 'Ljava/lang/String;', 'simpleStem',jword)
return(out)
}
stemWordWithLog <- function(Stemmer, word, outFile){
jword <- .jnew('java/lang/String', word)
joutFile <- .jnew('java/lang/String', outFile)
out   <- .jcall(Stemmer, 'S', 'stemWordAndLog',jword,joutFile,evalString = F, simplify = T)
return(out)
}
stemFile <- function(Stemmer, inFile, outFile){
f1 <- .jnew('java/lang/String',inFile)
f2 <- .jnew('java/lang/String',outFile)
.jcall(stemmer, 'V', 'stemFile',f1,f2)
}
# stemmer <- getArabicStemmer()
# stemWord(stemmer,"كلمة")
# stemWordWithLog(stemmer,"كلمة","out.txt")
# Sys.setlocale("LC_ALL", "Arabic")
stemmer <- getArabicStemmer()
stemWord(stemmer,"كلمة")
library(dplyr)
library(xlsx)
library(tm)
library(NLP)
library(caret)
source("utils.R",local = TRUE)
source("RArabicStemmer.R")
library(rJava)
getArabicStemmer <- function(){
.jinit('.')
.jaddClassPath("ArabicStemmer.jar")
Stemmer <- .jnew("elbeltagyRafea/SimpleArStemmer")
return(Stemmer)
}
stemWord <- function(word){
stemmer <-  getArabicStemmer()
jword <- .jnew('java/lang/String', word)
out   <- .jcall(stemmer, 'Ljava/lang/String;', 'simpleStem',jword)
return(out)
}
stemWordWithLog <- function(word, outFile){
stemmer <-  getArabicStemmer()
jword <- .jnew('java/lang/String', word)
joutFile <- .jnew('java/lang/String', outFile)
out   <- .jcall(stemmer, 'S', 'stemWordAndLog',jword,joutFile,evalString = F, simplify = T)
return(out)
}
stemFile <- function(inFile, outFile){
stemmer <-  getArabicStemmer()
f1 <- .jnew('java/lang/String',inFile)
f2 <- .jnew('java/lang/String',outFile)
.jcall(stemmer, 'V', 'stemFile',f1,f2)
}
#stemmer <- getArabicStemmer()
stemWord("كلمة")
# stemWordWithLog(stemmer,"كلمة","out.txt")
# Sys.setlocale("LC_ALL", "Arabic")
library(dplyr)
library(xlsx)
library(tm)
library(NLP)
library(caret)
source("utils.R",local = TRUE)
source("RArabicStemmer.R")
Sys.setlocale("LC_ALL", "Arabic")
set.seed(32323)
library(dplyr)
library(xlsx)
library(tm)
library(NLP)
library(caret)
source("utils.R",local = TRUE)
source("RArabicStemmer.R")
Sys.setlocale("LC_ALL", "Arabic")
set.seed(32323)
unclean.corpus <- read.csv("data/corpus_train.csv",encoding = "UTF-8")
#arabic.lexicon <- read.xlsx("data/sentimentLex.xlsx",sheetIndex = 1,encoding = "UTF-8")
arabic.stopword.df <- read.table("data/arabicStops.txt", encoding = "UTF-8")
arabic.stopword <- as.character((arabic.stopword.df$V1))
#str(unclean.corpus)
table(unclean.corpus$class)
stemmer <- getArabicStemmer()
twitter.corpus <- Corpus(VectorSource(unclean.corpus$tweet))
twitter.corpus.clean <- tm_map(twitter.corpus, tolower)
twitter.corpus.clean <- tm_map(twitter.corpus.clean, removeNumbers)
twitter.corpus.clean <- tm_map(twitter.corpus.clean, removeWords,arabic.stopword)
twitter.corpus.clean <- tm_map(twitter.corpus.clean, removePunctuation)
twitter.corpus.clean <- tm_map(twitter.corpus.clean, removeEnglishWords)
twitter.corpus.clean <- tm_map(twitter.corpus.clean, stripWhitespace)
twitter.corpus.clean <- tm_map(twitter.corpus.clean, reomveElongation)
twitter.corpus.clean <- tm_map(twitter.corpus.clean, reomveSingleLetters)
twitter.corpus.clean <- tm_map(twitter.corpus.clean, stemWord, stemmer )
stemmer <- getArabicStemmer()
twitter.corpus <- Corpus(VectorSource(unclean.corpus$tweet))
twitter.corpus.clean <- tm_map(twitter.corpus, tolower)
twitter.corpus.clean <- tm_map(twitter.corpus.clean, removeNumbers)
twitter.corpus.clean <- tm_map(twitter.corpus.clean, removeWords,arabic.stopword)
twitter.corpus.clean <- tm_map(twitter.corpus.clean, removePunctuation)
twitter.corpus.clean <- tm_map(twitter.corpus.clean, removeEnglishWords)
twitter.corpus.clean <- tm_map(twitter.corpus.clean, stripWhitespace)
twitter.corpus.clean <- tm_map(twitter.corpus.clean, reomveElongation)
twitter.corpus.clean <- tm_map(twitter.corpus.clean, reomveSingleLetters)
twitter.corpus.clean <- tm_map(twitter.corpus.clean, stemWord )
library(dplyr)
library(xlsx)
library(tm)
library(NLP)
library(caret)
source("utils.R",local = TRUE)
source("RArabicStemmer.R")
Sys.setlocale("LC_ALL", "Arabic")
set.seed(32323)
stemmer <- getArabicStemmer()
twitter.corpus <- Corpus(VectorSource(unclean.corpus$tweet))
twitter.corpus.clean <- tm_map(twitter.corpus, tolower)
twitter.corpus.clean <- tm_map(twitter.corpus.clean, removeNumbers)
twitter.corpus.clean <- tm_map(twitter.corpus.clean, removeWords,arabic.stopword)
twitter.corpus.clean <- tm_map(twitter.corpus.clean, removePunctuation)
twitter.corpus.clean <- tm_map(twitter.corpus.clean, removeEnglishWords)
twitter.corpus.clean <- tm_map(twitter.corpus.clean, stripWhitespace)
twitter.corpus.clean <- tm_map(twitter.corpus.clean, reomveElongation)
twitter.corpus.clean <- tm_map(twitter.corpus.clean, reomveSingleLetters)
twitter.corpus.clean <- tm_map(twitter.corpus.clean, stemWord )
source("RArabicStemmer.R")
stemmer <- getArabicStemmer()
twitter.corpus <- Corpus(VectorSource(unclean.corpus$tweet))
twitter.corpus.clean <- tm_map(twitter.corpus, tolower)
twitter.corpus.clean <- tm_map(twitter.corpus.clean, removeNumbers)
twitter.corpus.clean <- tm_map(twitter.corpus.clean, removeWords,arabic.stopword)
twitter.corpus.clean <- tm_map(twitter.corpus.clean, removePunctuation)
twitter.corpus.clean <- tm_map(twitter.corpus.clean, removeEnglishWords)
twitter.corpus.clean <- tm_map(twitter.corpus.clean, stripWhitespace)
twitter.corpus.clean <- tm_map(twitter.corpus.clean, reomveElongation)
twitter.corpus.clean <- tm_map(twitter.corpus.clean, reomveSingleLetters)
twitter.corpus.clean <- tm_map(twitter.corpus.clean, stemWord )
twitter.corpus.clean <- tm_map(twitter.corpus.clean, stemWord )
View(unclean.corpus)
unclean.corpus[1000]
stemWord("تشوف حد واحشك بقالك كتير مشفتوش♡ ")
as.data.frame(twitter.corpus.clean)
dataframe <- data.frame(text=sapply(twitter.corpus.clean,as.character),stringsAsFactors=F)
dataframe[1000]
dataframe[1000,]
dataframe[1001,]
class(dataframe[1001,])
stemWord(dataframe[1001,])
stemWord(dataframe[1000,])
?apply
dataframe <- data.frame(text=sapply(twitter.corpus.clean,as.character),stringsAsFactors=F)
twitter.corpus.clean <- apply(dataframe, 1, stemWord)
#write.xlsx(dataframe, "clean/twitter_clean_with_normalize.xlsx",sheetName = "sheet")
twitter.dtm <- DocumentTermMatrix(Corpus(DataframeSource(dataframe)))
inspect(twitter.dtm)
View(dataframe)
stemmer <- getArabicStemmer()
twitter.corpus <- Corpus(VectorSource(unclean.corpus$tweet))
twitter.corpus.clean <- tm_map(twitter.corpus, tolower)
twitter.corpus.clean <- tm_map(twitter.corpus.clean, removeNumbers)
twitter.corpus.clean <- tm_map(twitter.corpus.clean, removeWords,arabic.stopword)
twitter.corpus.clean <- tm_map(twitter.corpus.clean, removePunctuation)
twitter.corpus.clean <- tm_map(twitter.corpus.clean, removeEnglishWords)
twitter.corpus.clean <- tm_map(twitter.corpus.clean, stripWhitespace)
twitter.corpus.clean <- tm_map(twitter.corpus.clean, reomveElongation)
twitter.corpus.clean <- tm_map(twitter.corpus.clean, reomveSingleLetters)
inspect(twitter.corpus.clean[1:10])
dataframe <- data.frame(text=sapply(twitter.corpus.clean,as.character),stringsAsFactors=F)
write.table(dataframe$text, sep="\n", file = "in.txt")
twitter.corpus <- Corpus(VectorSource(unclean.corpus$tweet))
twitter.corpus.clean <- tm_map(twitter.corpus, tolower)
twitter.corpus.clean <- tm_map(twitter.corpus.clean, removeNumbers)
twitter.corpus.clean <- tm_map(twitter.corpus.clean, removeWords,arabic.stopword)
twitter.corpus.clean <- tm_map(twitter.corpus.clean, removePunctuation)
twitter.corpus.clean <- tm_map(twitter.corpus.clean, removeEnglishWords)
twitter.corpus.clean <- tm_map(twitter.corpus.clean, stripWhitespace)
twitter.corpus.clean <- tm_map(twitter.corpus.clean, reomveElongation)
twitter.corpus.clean <- tm_map(twitter.corpus.clean, reomveSingleLetters)
inspect(twitter.corpus.clean[1:10])
dataframe <- data.frame(text=sapply(twitter.corpus.clean,as.character),stringsAsFactors=F)
write.table(as.vector(dataframe$text), sep="\n", file = "in.txt", fileEncoding = "UTF-8")
as.vector(dataframe$text)
as.vector(dataframe$text)[1:10]
dataframe <- data.frame(text=sapply(twitter.corpus.clean,as.character),stringsAsFactors=F)
write.table((dataframe$text), sep="\n", file = "in.txt", fileEncoding = "UTF-8", col.names = F , row.names = F)
library(rJava)
getArabicStemmer <- function(){
.jinit('.')
.jaddClassPath("ArabicStemmer.jar")
Stemmer <- .jnew("elbeltagyRafea/SimpleArStemmer")
return(Stemmer)
}
stemWord <- function(word){
stemmer <-  getArabicStemmer()
#print(word)
jword <- .jnew('java/lang/String', word)
out   <- .jcall(stemmer, 'Ljava/lang/String;', 'simpleStem',jword)
return(out)
}
stemWordWithLog <- function(word, outFile){
stemmer <-  getArabicStemmer()
jword <- .jnew('java/lang/String', word)
joutFile <- .jnew('java/lang/String', outFile)
out   <- .jcall(stemmer, 'S', 'stemWordAndLog',jword,joutFile,evalString = F, simplify = T)
return(out)
}
stemFile <- function(inFile, outFile){
stemmer <-  getArabicStemmer()
f1 <- .jnew('java/lang/String',inFile)
f2 <- .jnew('java/lang/String',outFile)
.jcall(stemmer, 'V', 'stemFile',f1,f2)
}
#stemmer <- getArabicStemmer()
#stemWord("كلمة")
# stemWordWithLog(stemmer,"كلمة","out.txt")
# Sys.setlocale("LC_ALL", "Arabic")
library(rJava)
getArabicStemmer <- function(){
.jinit('.')
.jaddClassPath("ArabicStemmer.jar")
Stemmer <- .jnew("elbeltagyRafea/SimpleArStemmer")
return(Stemmer)
}
stemWord <- function(word){
stemmer <-  getArabicStemmer()
#print(word)
jword <- .jnew('java/lang/String', word)
out   <- .jcall(stemmer, 'Ljava/lang/String;', 'simpleStem',jword)
return(out)
}
stemWordWithLog <- function(word, outFile){
stemmer <-  getArabicStemmer()
jword <- .jnew('java/lang/String', word)
joutFile <- .jnew('java/lang/String', outFile)
out   <- .jcall(stemmer, 'S', 'stemWordAndLog',jword,joutFile,evalString = F, simplify = T)
return(out)
}
stemFile <- function(inFile, outFile){
stemmer <-  getArabicStemmer()
f1 <- .jnew('java/lang/String',inFile)
f2 <- .jnew('java/lang/String',outFile)
.jcall(stemmer, 'V', 'stemFile',f1,f2)
}
#stemmer <- getArabicStemmer()
#stemWord("كلمة")
# stemWordWithLog(stemmer,"كلمة","out.txt")
# Sys.setlocale("LC_ALL", "Arabic")
library(dplyr)
library(xlsx)
library(tm)
library(NLP)
library(caret)
source("utils.R",local = TRUE)
source("RArabicStemmer.R")
Sys.setlocale("LC_ALL", "Arabic")
set.seed(32323)
unclean.corpus <- read.csv("data/corpus_train.csv",encoding = "UTF-8")
#arabic.lexicon <- read.xlsx("data/sentimentLex.xlsx",sheetIndex = 1,encoding = "UTF-8")
arabic.stopword.df <- read.table("data/arabicStops.txt", encoding = "UTF-8")
arabic.stopword <- as.character((arabic.stopword.df$V1))
#str(unclean.corpus)
table(unclean.corpus$class)
twitter.corpus <- Corpus(VectorSource(unclean.corpus$tweet))
twitter.corpus.clean <- tm_map(twitter.corpus, tolower)
twitter.corpus.clean <- tm_map(twitter.corpus.clean, removeNumbers)
twitter.corpus.clean <- tm_map(twitter.corpus.clean, removeWords,arabic.stopword)
twitter.corpus.clean <- tm_map(twitter.corpus.clean, removePunctuation)
twitter.corpus.clean <- tm_map(twitter.corpus.clean, removeEnglishWords)
twitter.corpus.clean <- tm_map(twitter.corpus.clean, stripWhitespace)
twitter.corpus.clean <- tm_map(twitter.corpus.clean, reomveElongation)
twitter.corpus.clean <- tm_map(twitter.corpus.clean, reomveSingleLetters)
inspect(twitter.corpus.clean[1:10])
dataframe <- data.frame(text=sapply(twitter.corpus.clean,as.character),stringsAsFactors=F)
write.table(dataframe$text, sep="\n", file = "in.txt", fileEncoding = "UTF-8", col.names = F , row.names = F)
stemFile("in.txt", "out.txt")
dataframe <- read.table("out.txt", sep="\n", fileEncoding = "UTF-8")
#write.xlsx(dataframe, "clean/twitter_clean_with_normalize.xlsx",sheetName = "sheet")
twitter.dtm <- DocumentTermMatrix(Corpus(DataframeSource(dataframe)))
inspect(twitter.dtm)
twitter.dict <- findFreqTerms(twitter.dtm, 5)
#print(twitter.dict)
twitter.df <- DocumentTermMatrix(Corpus(DataframeSource(dataframe)),
list(dictionary = twitter.dict))
inspect(twitter.df)
twitter.df <- apply(twitter.df, MARGIN = 2, convertCounts)
twitter.df <- as.data.frame(twitter.df)
twitter.df$Class <- as.character(unclean.corpus$class)
twitter.dict <- findFreqTerms(twitter.dtm, 5)
#print(twitter.dict)
twitter.df <- DocumentTermMatrix(Corpus(DataframeSource(dataframe)),
list(dictionary = twitter.dict))
inspect(twitter.df)
twitter.df <- apply(twitter.df, MARGIN = 2, convertCounts)
twitter.df <- as.data.frame(twitter.df)
twitter.df$Class <- as.character(unclean.corpus$class[-1420])
length(unclean.corpus$class[-1420])
length(unclean.corpus$class)
twitter.df[1421,]
twitter.dict <- findFreqTerms(twitter.dtm, 5)
#print(twitter.dict)
twitter.df <- DocumentTermMatrix(Corpus(DataframeSource(dataframe)),
list(dictionary = twitter.dict))
inspect(twitter.df)
twitter.df <- apply(twitter.df, MARGIN = 2, convertCounts)
twitter.df <- as.data.frame(twitter.df)
twitter.df <- twitter.df[-1420,]
twitter.df$Class <- as.character(unclean.corpus$class)
dataframe <- read.table("out.txt", sep="\n", fileEncoding = "UTF-8")
#write.xlsx(dataframe, "clean/twitter_clean_with_normalize.xlsx",sheetName = "sheet")
twitter.dtm <- DocumentTermMatrix(Corpus(DataframeSource(dataframe)))
inspect(twitter.dtm)
twitter.corpus <- Corpus(VectorSource(unclean.corpus$tweet))
twitter.corpus.clean <- tm_map(twitter.corpus, tolower)
twitter.corpus.clean <- tm_map(twitter.corpus.clean, removeNumbers)
twitter.corpus.clean <- tm_map(twitter.corpus.clean, removeWords,arabic.stopword)
twitter.corpus.clean <- tm_map(twitter.corpus.clean, removePunctuation)
twitter.corpus.clean <- tm_map(twitter.corpus.clean, removeEnglishWords)
twitter.corpus.clean <- tm_map(twitter.corpus.clean, stripWhitespace)
twitter.corpus.clean <- tm_map(twitter.corpus.clean, reomveElongation)
twitter.corpus.clean <- tm_map(twitter.corpus.clean, reomveSingleLetters)
dataframe <- data.frame(text=sapply(twitter.corpus.clean,as.character),stringsAsFactors=F)
write.table(dataframe$text, sep="\n", file = "in.txt", fileEncoding = "UTF-8", col.names = F , row.names = F)
stemFile("in.txt", "out.txt")
dataframe <- read.table("out.txt", sep="\n", fileEncoding = "UTF-8")
#write.xlsx(dataframe, "clean/twitter_clean_with_normalize.xlsx",sheetName = "sheet")
twitter.dtm <- DocumentTermMatrix(Corpus(DataframeSource(dataframe)))
inspect(twitter.dtm)
